{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8lqbeWAze76Q",
    "outputId": "b3a1293d-7c66-4d33-87a3-f987dfc5d9b8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install pygad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu_yNfc2kEBP"
   },
   "source": [
    "model inspired and modified from http://uhurumkate.blogspot.com/2018/06/tiny-model-for-mnist-dataset.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're highly encouraged to use a GPU as it's going to spent most resources on predicting and calculating acc. Please also note that pygad library only use cpu paralleal in some cases. <br>\n",
    "P.S.2 It takes painfully long to converage. About an hour per 10% increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5L3JMNgS-L0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import losses, datasets, layers, optimizers, Sequential, metrics\n",
    "import pygad.kerasga\n",
    "import numpy\n",
    "import pygad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGFxRvr3eWGX"
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(123)\n",
    "acc_meter = tf.keras.metrics.Accuracy()\n",
    "\n",
    "#Instead of training a entire dataset, do small batches.\n",
    "sgd_like = False\n",
    "\n",
    "#Introduce new population when stucked\n",
    "introduce_new_when_stucked = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm_Hl7BAgrzv"
   },
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Rkq5w4dequA"
   },
   "outputs": [],
   "source": [
    "#load mnist dataset\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "#normalize data\n",
    "X_train = 2*tf.convert_to_tensor(X_train, tf.float32)/255.-1\n",
    "#[b, 28, 28] -> [b, 28, 28, 1]\n",
    "X_train = tf.reshape(X_train, (-1, 28,28,1))\n",
    "X_test = 2*tf.convert_to_tensor(X_test, tf.float32)/255.-1\n",
    "X_test = tf.reshape(X_test, (-1, 28,28,1))\n",
    "y_train = tf.convert_to_tensor(y_train, tf.int32)\n",
    "#[b] -> [b, 10]\n",
    "y_train = tf.one_hot(y_train, 10)\n",
    "y_test = tf.convert_to_tensor(y_test, tf.int32)\n",
    "y_test = tf.one_hot(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGsLcsClp1P6"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYvgt7ULiR5L"
   },
   "source": [
    "We want a very small model for the increase in param will increase the cycles GA needs to run </ba>\n",
    "Model parameter = 1810 with acc ~ 96% on both train/testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dW1AXe0zci0T",
    "outputId": "060845b2-7c92-44ce-8d5f-ec4c976f58d7"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "#input layer\n",
    "layers.Convolution2D(15, (3, 3), activation='relu', input_shape=(28,28,1)),\n",
    "layers.BatchNormalization(momentum=0.1),\n",
    "layers.Dropout(0.1),\n",
    "layers.AveragePooling2D(2),\n",
    "#convo layers1\n",
    "layers.Convolution2D(10,(1,1), activation='relu'),\n",
    "layers.BatchNormalization(momentum=0.1),\n",
    "layers.Dropout(0.1),\n",
    "#convo layers2\n",
    "layers.AveragePooling2D(2),\n",
    "layers.Convolution2D(5,(3,3), activation='relu'),\n",
    "layers.BatchNormalization(momentum=0.1),\n",
    "layers.Dropout(0.1),\n",
    "#convo layers3\n",
    "layers.Convolution2D(10,(1,1), activation='relu'),\n",
    "layers.Dropout(0.1),\n",
    "#fully connected layers\n",
    "layers.Dense(5, activation='relu'),\n",
    "layers.Flatten(),\n",
    "#output layer\n",
    "layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uy2Zi5Wdip3p"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "#model.fit(X_train, y_train, \n",
    "#          batch_size=8, verbose=1,shuffle=True,\n",
    "#          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YV6R1V52ptP7"
   },
   "source": [
    "Network accuracy and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSVRcjVijtHY",
    "outputId": "3a2c3922-e8f1-47c1-98f1-94256e43e86d"
   },
   "outputs": [],
   "source": [
    "acc_meter.update_state(tf.argmax(model.predict(X_test), axis=1), tf.argmax(y_test, axis=1))\n",
    "print(\"Accuracy on testing set:{acc}%\".format(acc=acc_meter.result().numpy()*100))\n",
    "print(\"Error rate on testing set:{err}%\".format(err=(1-acc_meter.result().numpy())*100))\n",
    "acc_meter.update_state(tf.argmax(model.predict(X_train), axis=1), tf.argmax(y_train, axis=1))\n",
    "print(\"Accuracy on training set:{acc}%\".format(acc=acc_meter.result().numpy()*100))\n",
    "print(\"Error rate on training set:{err}%\".format(err=(1-acc_meter.result().numpy())*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ptOJ9miprDS"
   },
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_omnjFA5lOh"
   },
   "outputs": [],
   "source": [
    "#cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "#cce(y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1Q4nna4YeCz"
   },
   "outputs": [],
   "source": [
    "#we don't need one-hot to train. To compute tf.argmax each loop is a waste of resources\n",
    "y_train = tf.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYoIXfZjp4kJ"
   },
   "source": [
    "Perpare batches if we were doing SGD-like method. <br>\n",
    "Some data are removed if size of dataset / batch_size is not an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_V7t28kieeVR"
   },
   "outputs": [],
   "source": [
    "X_train_sgd = []\n",
    "y_train_sgd = []\n",
    "if sgd_like == True:\n",
    "  batch_size = 3000\n",
    "  if len(X_train) % batch_size == 0:\n",
    "    X_train_sgd = tf.reshape(X_train, [-1, batch_size, 28, 28, 1])\n",
    "    y_train_sgd = tf.reshape(y_train, [-1, batch_size])\n",
    "  else:\n",
    "    len_remove = len(X_train) % batch_size\n",
    "    X_train_sgd = tf.reshape(X_train[:-len_remove], [-1, batch_size, 28, 28, 1])\n",
    "    y_train_sgd = tf.reshape(y_train[:-len_remove], [-1, batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdZ1owxPPsRn"
   },
   "source": [
    "# Hyper param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hl1q_FZnfTG1"
   },
   "outputs": [],
   "source": [
    "#num cycles\n",
    "num_generations = 1000\n",
    "\n",
    "#num solutions\n",
    "num_solution=10\n",
    "\n",
    "#the following two param have no effect when introduce_new_when_stucked = false\n",
    "#Maxium cycles stuck before introducing new population to the pool.\n",
    "max_cycles_stucked = 400\n",
    "#number of population to be reinitlized. Much be >0 and  <= num_generations.\n",
    "num_reintroduce = 3\n",
    "\n",
    "#number of cycles you want on a single batch. Only works when sgd_like = True\n",
    "epoch = 100\n",
    "\n",
    "#70 % parents mating\n",
    "num_parents_mating = int(num_solution * .7)\n",
    "parent_selection_type = \"sss\"\n",
    "crossover_type = \"uniform\"\n",
    "mutation_type=\"adaptive\"\n",
    "mutation_num_genes=(90, 80)\n",
    "keep_parents = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROmBNKL2Pw2u"
   },
   "source": [
    "# Fitness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuGqTK0NeeVR"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "cycles_stucked = 0\n",
    "tmp = 0\n",
    "\n",
    "def fitness_func(solution, sol_idx):\n",
    "\n",
    "    global keras_ga, model, i, cycles_stucked ,X_train, y_train\n",
    "    solution_fitness = 0\n",
    "    model_weights_matrix = pygad.kerasga.model_weights_as_matrix(model=model,\n",
    "                                                                 weights_vector=solution)\n",
    "\n",
    "    model.set_weights(weights=model_weights_matrix)\n",
    "    \n",
    "    #introduce new population to the pool if reached max cycles stucked. Max_cycles_stucked -> 0.\n",
    "    if introduce_new_when_stucked:\n",
    "        if cycles_stucked == max_cycles_stucked:\n",
    "            ga_instance.population[:3] = tf.random.truncated_normal(ga_instance.population[:3].shape)\n",
    "            cycles_stucked = 0\n",
    "\n",
    "    #solution_fitness = 1/cce(model.predict(X_train), y_train).numpy()\n",
    "    \n",
    "    if sgd_like == True:\n",
    "        if i % (1 * epoch) == 0:\n",
    "            #selec.t random data from reshaped dataset to train\n",
    "            k = numpy.random.randint(0, len(X_train_sgd)-1)\n",
    "            #update acc_meter\n",
    "            acc_meter.update_state(tf.argmax(model.predict(X_train_sgd[k]), axis=1), y_train_sgd[k])\n",
    "            solution_fitness = acc_meter.result().numpy() * 100\n",
    "            acc_meter.reset_states()\n",
    "    else:\n",
    "        acc_meter.update_state(tf.argmax(model.predict(X_train), axis=1), y_train)\n",
    "        solution_fitness = acc_meter.result().numpy() * 100\n",
    "        acc_meter.reset_states()\n",
    "    return solution_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0e-_WFceeVS",
    "outputId": "c1763309-89d1-439f-d874-7bf9f3007d97"
   },
   "outputs": [],
   "source": [
    "def callback_generation(ga_instance):\n",
    "    global i, cycles_stucked, tmp\n",
    "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
    "    print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
    "    i += 1\n",
    "    if ga_instance.best_solution()[1] == tmp:\n",
    "        cycles_stucked += 1\n",
    "    else:\n",
    "        cycles_stucked = 0\n",
    "    tmp = ga_instance.best_solution()[1]\n",
    "    \n",
    "\n",
    "\n",
    "keras_ga = pygad.kerasga.KerasGA(model=model,\n",
    "                                 num_solutions=num_solution)\n",
    "\n",
    "\n",
    "# Prepare the PyGAD parameters. Check the documentation for more information: https://pygad.readthedocs.io/en/latest/README_pygad_ReadTheDocs.html#pygad-ga-class\n",
    "# Use the pre-existing model weight as init population. \n",
    "initial_population = numpy.tile(pygad.kerasga.model_weights_as_vector(model), (num_solution, 1))\n",
    "\n",
    "\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       initial_population=initial_population,\n",
    "                       fitness_func=fitness_func,\n",
    "                       keep_parents=keep_parents,\n",
    "                       mutation_type=mutation_type,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_num_genes=mutation_num_genes,\n",
    "                       on_generation=callback_generation)\n",
    "ga_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKFLa_wLeeVT"
   },
   "outputs": [],
   "source": [
    "\n",
    "# After the generations complete, some plots are showed that summarize how the outputs/fitness values evolve over generations.\n",
    "ga_instance.plot_fitness(title=\"PyGAD & Keras - Iteration vs. Fitness\", linewidth=4)\n",
    "\n",
    "# Returning the details of the best solution.\n",
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\n",
    "print(\"Index of the best solution : {solution_idx}\".format(solution_idx=solution_idx))\n",
    "\n",
    "# Fetch the parameters of the best solution.\n",
    "best_solution_weights = pygad.kerasga.model_weights_as_matrix(model=model,\n",
    "                                                              weights_vector=solution)\n",
    "model.set_weights(best_solution_weights)\n",
    "\n",
    "acc_meter.update_state(tf.argmax(model.predict(X_test), axis=1), tf.argmax(y_test, axis=1))\n",
    "print(\"Accuracy on testing set:{acc}%\".format(acc=acc_meter.result().numpy()*100))\n",
    "print(\"Error rate on testing set:{err}%\".format(err=(1-acc_meter.result().numpy())*100))\n",
    "\n",
    "acc_meter.update_state(tf.argmax(model.predict(X_train), axis=1), y_train)\n",
    "print(\"Accuracy on training set:{acc}%\".format(acc=acc_meter.result().numpy()*100))\n",
    "print(\"Error rate on training set:{err}%\".format(err=(1-acc_meter.result().numpy())*100))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of kerasGA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
